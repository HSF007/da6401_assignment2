{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ffd2a9dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import os\n",
    "import wandb\n",
    "import numpy as np\n",
    "import torch\n",
    "import random\n",
    "import torch.nn as nn\n",
    "from PIL import Image\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import Dataset, DataLoader, Subset, random_split\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay, classification_report"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9027cafb",
   "metadata": {},
   "source": [
    "## Question 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0a703f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNNModel(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        input_channels=3,\n",
    "        filters_per_layer=[32, 64, 128, 256, 512],\n",
    "        kernel_size=3,\n",
    "        pool_sizes=2,\n",
    "        conv_activation='relu',\n",
    "        dense_units=256,\n",
    "        dense_activation='relu',\n",
    "        num_classes=10,\n",
    "        dropout_rate=0.5,\n",
    "        use_batch_norm=True\n",
    "    ):\n",
    "        \n",
    "        super().__init__()\n",
    "        \n",
    "        self.kernel_size = kernel_size\n",
    "        self.pool_sizes = pool_sizes\n",
    "        self.conv_activation = conv_activation\n",
    "        self.dense_activation = dense_activation\n",
    "\n",
    "        # Initializing Convolutional, Batch Norm, and pooling layers\n",
    "        self.conv_layers = nn.ModuleList()\n",
    "        self.batch_norm_layers = nn.ModuleList()\n",
    "        self.pool_layers = nn.ModuleList()\n",
    "        \n",
    "        in_channels = input_channels\n",
    "        \n",
    "        # Create 5 convolutional blocks\n",
    "        for filters in filters_per_layer:\n",
    "            # Convolutional layer\n",
    "            self.conv_layers.append(\n",
    "                nn.Conv2d(\n",
    "                    in_channels=in_channels,\n",
    "                    out_channels=filters,\n",
    "                    kernel_size=kernel_size,\n",
    "                    padding=\"same\",\n",
    "                )\n",
    "            )\n",
    "            \n",
    "            # Batch normalization layer\n",
    "            if use_batch_norm:\n",
    "                self.batch_norm_layers.append(nn.BatchNorm2d(filters))\n",
    "            else:\n",
    "                self.batch_norm_layers.append(None)\n",
    "            \n",
    "            # Max pooling layer\n",
    "            self.pool_layers.append(nn.MaxPool2d(kernel_size=2, stride=2))\n",
    "            \n",
    "            # Update in_channels for next layer\n",
    "            in_channels = filters\n",
    "        \n",
    "        # Calculate the output size after conv layers\n",
    "        # Assuming input is 224x224, after 5 max-pooling layers it will be 7x7\n",
    "        conv_output_size = 7 * 7 * filters_per_layer[-1]\n",
    "        \n",
    "        # First flatten the image to pass it to the dense layer\n",
    "        self.flatten = nn.Flatten()\n",
    "\n",
    "        # Dense layer\n",
    "        self.fc1 = nn.Linear(conv_output_size, dense_units)\n",
    "        self.fc_bn = nn.BatchNorm1d(dense_units) if use_batch_norm else None\n",
    "        self.dropout1 = nn.Dropout(dropout_rate)\n",
    "        \n",
    "        # Output layer\n",
    "        self.fc2 = nn.Linear(dense_units, num_classes)\n",
    "        self.dropout2 = nn.Dropout(dropout_rate)\n",
    "    \n",
    "    def activation_func(self, activation, x):\n",
    "        \"\"\"Apply the selected activation function\"\"\"\n",
    "        if activation.lower() == 'relu':\n",
    "            return F.relu(x)\n",
    "        elif activation.lower() == 'gelu':\n",
    "            return F.gelu(x)\n",
    "        elif activation.lower() == 'silu' or activation.lower() == 'swish':\n",
    "            return F.silu(x)\n",
    "        elif activation.lower() == 'mish':\n",
    "            return x * torch.tanh(F.softplus(x))\n",
    "            return F.sigmoid(x)\n",
    "        elif activation.lower() == 'leakyrelu':\n",
    "            return F.leaky_relu(x, negative_slope=0.01)\n",
    "        else:\n",
    "            # Default to ReLU\n",
    "            return F.relu(x)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        \"\"\"Forward pass through the network\"\"\"\n",
    "        # Convolutional blocks\n",
    "        for i, (conv, bn, pool) in enumerate(zip(self.conv_layers, self.batch_norm_layers, self.pool_layers)):\n",
    "            x = conv(x)\n",
    "            if bn is not None:\n",
    "                x = bn(x)\n",
    "            x = self.activation_func(self.conv_activation, x)\n",
    "            x = pool(x)\n",
    "        \n",
    "        # Flatten\n",
    "        x = self.flatten(x)\n",
    "        # x = torch.flatten(x, 1)\n",
    "        \n",
    "        # Dense layer\n",
    "        x = self.fc1(x)\n",
    "        if self.fc_bn is not None:\n",
    "            x = self.fc_bn(x)\n",
    "        x = self.activation_func(self.dense_activation, x)\n",
    "        x = self.dropout1(x)\n",
    "        \n",
    "        # Output layer\n",
    "        x = self.fc2(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba113d2e",
   "metadata": {},
   "source": [
    "## Question 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33cc514a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set random seeds for reproducibility\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)\n",
    "random.seed(42)\n",
    "\n",
    "# Data paths\n",
    "DATASET_PATH = r\"E:\\IITM\\2nd sem\\inaturalist_12K\"  # Update with your path\n",
    "TRAIN_DIR = os.path.join(DATASET_PATH, \"train\")\n",
    "TEST_DIR = os.path.join(DATASET_PATH, \"val\")\n",
    "\n",
    "# Check if CUDA is available\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee4e6318",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameter sweep configuration\n",
    "sweep_config = {\n",
    "    'method': 'bayes',\n",
    "    'metric': {\n",
    "        'name': 'val_accuracy',\n",
    "        'goal': 'maximize'\n",
    "    },\n",
    "    'parameters': {\n",
    "        'base_filters': {'values': [32, 64]},\n",
    "        'conv_activation': {'values': ['relu', 'gelu', 'silu', 'mish']},\n",
    "        'dense_activation': {'values':['relu', 'gelu', 'silu', 'leakyrelu']},\n",
    "        'filter_organization': {'values': ['same', 'doubling', 'halving']},\n",
    "        'data_augmentation': {'values': [True, False]},\n",
    "        'use_batch_norm': {'values': [True, False]},\n",
    "        'dropout_rate': {'values': [0, 0.2, 0.3, 0.5]},\n",
    "        'dense_neurons': {'values': [128, 256, 512, 1024]},\n",
    "        'learning_rate': {'values': [0.0001, 0.001, 0.01]},\n",
    "        'epochs': {'value': 10},\n",
    "        'batch_size': {'value': 32},\n",
    "        'image_size': {'value': 224},\n",
    "        'validation_split': {'value': 0.2}\n",
    "    }\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6ac2b5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class iNaturalistDataset(Dataset):\n",
    "    \"\"\"Custom Dataset for iNaturalist images.\"\"\"\n",
    "    \n",
    "    def __init__(self, root_dir, transform=None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            root_dir (string): Directory with class subdirectories.\n",
    "            transform (callable, optional): Optional transform to be applied on a sample.\n",
    "        \"\"\"\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "        \n",
    "        # Get class directories and create class-to-idx mapping\n",
    "        self.classes = sorted([d for d in os.listdir(root_dir) \n",
    "                              if os.path.isdir(os.path.join(root_dir, d))])\n",
    "        self.class_to_idx = {cls_name: i for i, cls_name in enumerate(self.classes)}\n",
    "        \n",
    "        # Get all image paths and corresponding labels\n",
    "        self.image_paths = []\n",
    "        self.labels = []\n",
    "        \n",
    "        for class_name in self.classes:\n",
    "            class_dir = os.path.join(root_dir, class_name)\n",
    "            for img_name in os.listdir(class_dir):\n",
    "                if img_name.lower().endswith(('.png', '.jpg', '.jpeg')):\n",
    "                    self.image_paths.append(os.path.join(class_dir, img_name))\n",
    "                    self.labels.append(self.class_to_idx[class_name])\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.image_paths[idx]\n",
    "        image = Image.open(img_path).convert('RGB')\n",
    "        label = self.labels[idx]\n",
    "        \n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        \n",
    "        return image, label\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "395133eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_split_data(config):\n",
    "    \"\"\"\n",
    "    Load data and split into train and validation sets,\n",
    "    ensuring equal class representation in validation set.\n",
    "    \"\"\"\n",
    "    # Base transforms\n",
    "    base_transform = transforms.Compose([\n",
    "        transforms.Resize((config.image_size, config.image_size)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "    ])\n",
    "    \n",
    "    # Data augmentation transform\n",
    "    augment_transform = transforms.Compose([\n",
    "        transforms.Resize((config.image_size, config.image_size)),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.RandomRotation(20),\n",
    "        transforms.ColorJitter(brightness=0.1, contrast=0.1, saturation=0.1, hue=0.1),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "    ])\n",
    "    \n",
    "    # Choose transform based on config\n",
    "    train_transform = augment_transform if config.data_augmentation else base_transform\n",
    "    \n",
    "    # Load dataset\n",
    "    full_dataset = iNaturalistDataset(root_dir=TRAIN_DIR, transform=train_transform)\n",
    "    val_dataset = iNaturalistDataset(root_dir=TRAIN_DIR, transform=base_transform)\n",
    "    test_datase = iNaturalistDataset(root_dir=TEST_DIR, transform=base_transform)\n",
    "    \n",
    "    # Get class counts for stratified split\n",
    "    class_counts = {}\n",
    "    for label in full_dataset.labels:\n",
    "        if label not in class_counts:\n",
    "            class_counts[label] = 0\n",
    "        class_counts[label] += 1\n",
    "    \n",
    "    # Create stratified split\n",
    "    train_indices = []\n",
    "    val_indices = []\n",
    "    \n",
    "    for class_idx in range(len(full_dataset.classes)):\n",
    "        # Get indices for this class\n",
    "        class_indices = [i for i, label in enumerate(full_dataset.labels) if label == class_idx]\n",
    "        np.random.shuffle(class_indices)\n",
    "        \n",
    "        # Split indices\n",
    "        val_count = int(len(class_indices) * config.validation_split)\n",
    "        val_indices.extend(class_indices[:val_count])\n",
    "        train_indices.extend(class_indices[val_count:])\n",
    "    \n",
    "    # Create subset datasets\n",
    "    train_dataset = Subset(full_dataset, train_indices)\n",
    "    val_dataset = Subset(val_dataset, val_indices)\n",
    "    \n",
    "    print(f\"Total training samples: {len(train_dataset)}\")\n",
    "    print(f\"Total validation samples: {len(val_dataset)}\")\n",
    "    \n",
    "    # Create data loaders\n",
    "    train_loader = DataLoader(\n",
    "        train_dataset, \n",
    "        batch_size=config.batch_size,\n",
    "        shuffle=True,\n",
    "        num_workers=4,\n",
    "        pin_memory=True\n",
    "    )\n",
    "    \n",
    "    val_loader = DataLoader(\n",
    "        val_dataset,\n",
    "        batch_size=config.batch_size,\n",
    "        shuffle=False,\n",
    "        num_workers=4,\n",
    "        pin_memory=True\n",
    "    )\n",
    "    \n",
    "    test_loader = DataLoader(\n",
    "        test_datase,\n",
    "        batch_size=config.batch_size,\n",
    "        shuffle=False,\n",
    "        num_workers=4,\n",
    "        pin_memory=True\n",
    "    )\n",
    "    \n",
    "    return train_loader, val_loader, test_loader, len(full_dataset.classes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b0d4fcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(config):\n",
    "    \"\"\"Train the model with current hyperparameter configuration.\"\"\"\n",
    "    # Load and split data\n",
    "    train_loader, val_loader, test_loader, num_classes = load_and_split_data(config)\n",
    "    \n",
    "    # Create model based on hyperparameters\n",
    "    if config.filter_organization == 'same':\n",
    "        filters = [config.base_filters] * 5\n",
    "    elif config.filter_organization == 'doubling':\n",
    "        filters = [config.base_filters * (2**i) for i in range(5)]\n",
    "    elif config.filter_organization == 'halving':\n",
    "        filters = [config.base_filters * (2**(4-i)) for i in range(5)]\n",
    "    else:\n",
    "        filters = [32, 64, 128, 256, 512]  # Default\n",
    "    \n",
    "    model = CNNModel(\n",
    "        input_channels=3,\n",
    "        num_classes=num_classes,\n",
    "        filters_per_layer=filters,\n",
    "        kernel_size=3,\n",
    "        conv_activation=config.conv_activation,\n",
    "        dense_units=config.dense_neurons,\n",
    "        dense_activation = config.dense_activation,\n",
    "        dropout_rate=config.dropout_rate,\n",
    "        use_batch_norm=config.use_batch_norm\n",
    "    )\n",
    "    \n",
    "    # Move model to device\n",
    "    model = model.to(device)\n",
    "    \n",
    "    # Define loss function and optimizer\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=config.learning_rate)\n",
    "    \n",
    "    # Initialize WandB for tracking\n",
    "    wandb.watch(model, criterion, log=\"all\", log_freq=100)\n",
    "    \n",
    "    # Training loop\n",
    "    best_val_acc = 0.0\n",
    "    \n",
    "    for epoch in range(config.epochs):\n",
    "        # Training phase\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        \n",
    "        for i, (inputs, labels) in enumerate(train_loader):\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            \n",
    "            # Zero the parameter gradients\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            # Forward pass\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            \n",
    "            # Backward pass and optimize\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            # Statistics\n",
    "            _, predicted = outputs.max(1)\n",
    "            total += labels.size(0)\n",
    "            correct += predicted.eq(labels).sum().item()\n",
    "        \n",
    "        train_acc = correct / total\n",
    "        \n",
    "        # Validation phase\n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        val_correct = 0\n",
    "        val_total = 0\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for inputs, labels in val_loader:\n",
    "                inputs, labels = inputs.to(device), labels.to(device)\n",
    "                outputs = model(inputs)\n",
    "                loss = criterion(outputs, labels)\n",
    "                \n",
    "                val_loss += loss.item()\n",
    "                _, predicted = outputs.max(1)\n",
    "                val_total += labels.size(0)\n",
    "                val_correct += predicted.eq(labels).sum().item()\n",
    "        \n",
    "        val_acc = val_correct / val_total\n",
    "        \n",
    "        # Log metrics to wandb\n",
    "        wandb.log({\n",
    "            \"epoch\": epoch + 1,\n",
    "            \"train_loss\": running_loss / len(train_loader),\n",
    "            \"train_accuracy\": train_acc,\n",
    "            \"val_loss\": val_loss / len(val_loader),\n",
    "            \"val_accuracy\": val_acc\n",
    "        })\n",
    "        \n",
    "        print(f'Epoch: {epoch + 1}, Val Loss: {val_loss / len(val_loader):.3f}, Val Acc: {100 * val_acc:.2f}%')\n",
    "        \n",
    "        # Save the best model\n",
    "        if val_acc > best_val_acc:\n",
    "            best_val_acc = val_acc\n",
    "            # Save the model\n",
    "            torch.save(model, f\"best_model_{wandb.run.id}.pth\")\n",
    "            # Log the model to wandb\n",
    "            artifact = wandb.Artifact('model', type='model')\n",
    "            artifact.add_file(f\"best_model_{wandb.run.id}.pth\")\n",
    "            wandb.log_artifact(artifact)\n",
    "    \n",
    "    model.eval()\n",
    "    test_correct = 0\n",
    "    test_total = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in test_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            outputs = model(inputs)\n",
    "            _, predicted = outputs.max(1)\n",
    "            test_total += labels.size(0)\n",
    "            test_correct += predicted.eq(labels).sum().item()\n",
    "    \n",
    "    test_acc = test_correct / test_total\n",
    "    print(f'Test Accuracy: {100 * test_acc:.2f}%')\n",
    "    wandb.log({\"test_accuracy\": test_acc})\n",
    "    \n",
    "    # Save final model\n",
    "    torch.save(model, f\"final_model_{wandb.run.id}.pth\")\n",
    "\n",
    "    # Log the model to wandb\n",
    "    artifact = wandb.Artifact('model', type='model')\n",
    "    artifact.add_file(f\"final_model_{wandb.run.id}.pth\")\n",
    "    wandb.log_artifact(artifact)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fe58d37",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sweep_train():\n",
    "    \"\"\"Configure and run hyperparameter sweep.\"\"\"\n",
    "    # Initialize wandb\n",
    "    wandb.init()\n",
    "\n",
    "    # Configuration parameters\n",
    "    config = wandb.config\n",
    "\n",
    "    # Set run name based on hyperparameters\n",
    "    run_name = f'bf_{config.base_filters}_fo_{config.filter_organization}_dn_{config.dense_neurons}_ca_{config.conv_activation}_da_{config.dense_activation}_v5'\n",
    "    wandb.run.name = run_name\n",
    "\n",
    "    # Call training function with current hyperparameters\n",
    "    train_model(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b66cb20c",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    sweep_id = wandb.sweep(sweep=sweep_config, project=\"DA6401-A2-V4\")\n",
    "    \n",
    "    wandb.agent(sweep_id, sweep_train, count=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "892718f8",
   "metadata": {},
   "source": [
    "## Question 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9a06a16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to the test data\n",
    "DATASET_PATH = r\"E:\\IITM\\2nd sem\\inaturalist_12K\"  # Update with your path\n",
    "TEST_DIR = os.path.join(DATASET_PATH, \"val\")\n",
    "\n",
    "# Set device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Image size\n",
    "IMAGE_SIZE = 224\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "243d747a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_best_run_from_sweep(sweep_id, entity, project):\n",
    "    api = wandb.Api()\n",
    "    \n",
    "    sweep = api.sweep(f\"{entity}/{project}/{sweep_id}\")\n",
    "    \n",
    "    best_val_acc = -1\n",
    "    best_run = None\n",
    "    \n",
    "    for run in sweep.runs:\n",
    "        val_acc = run.summary.get(\"val_accuracy\")\n",
    "        if val_acc is not None and val_acc > best_val_acc:\n",
    "            best_val_acc = val_acc\n",
    "            best_run = run\n",
    "    \n",
    "    if best_run is None:\n",
    "        raise ValueError(\"No runs with 'val_accuracy' found in the sweep\")\n",
    "    \n",
    "    print(f\"Best run: {best_run.name}, val_accuracy: {best_val_acc:.4f}\")\n",
    "    return best_run\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7233a170",
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_best_model(run, artifact_name=\"model\", output_dir=\"downloaded_model\"):\n",
    "    \"\"\"\n",
    "    Download the best model file from wandb.\n",
    "    \n",
    "    Args:\n",
    "        best_run: The wandb run object for the best run\n",
    "    \n",
    "    Returns:\n",
    "        model_path: Local path to the downloaded model\n",
    "        config: Configuration of the best model\n",
    "    \"\"\"\n",
    "    api = wandb.Api()\n",
    "\n",
    "    # List all artifacts with this name in the project\n",
    "    artifact_versions = api.artifacts(name=f\"{run.project}/{artifact_name}\", type_name='model')\n",
    "    \n",
    "    for artifact in artifact_versions:\n",
    "        # Match the artifact to the run that created it\n",
    "        if artifact.logged_by and artifact.logged_by().id == run.id:\n",
    "            print(f\"Found artifact version: {artifact.version} from run: {run.name}\")\n",
    "            artifact_dir = artifact.download(root=output_dir)\n",
    "            for file_name in os.listdir(artifact_dir):\n",
    "                print(file_name)\n",
    "                if file_name.startswith(\"final_model\") and file_name.endswith(\".pth\"):\n",
    "                    model_path = os.path.join(artifact_dir, file_name)\n",
    "                    print(f\"Downloaded model file: {model_path}\")\n",
    "    \n",
    "    print(f\"Downloaded model file: {model_path}\")\n",
    "    \n",
    "    # Get the model configuration from the run\n",
    "    config = {\n",
    "        'base_filters': run.config.get('base_filters', 32),\n",
    "        'dense_activation': run.config.get('dense_activation', 'relu'),\n",
    "        'filter_organization': run.config.get('filter_organization', 'doubling'),\n",
    "        'dense_neurons': run.config.get('dense_neurons', 512),\n",
    "        'dropout_rate': run.config.get('dropout_rate', 0.3),\n",
    "        'use_batch_norm': run.config.get('use_batch_norm', True),\n",
    "        'conv_activation': run.config.get('conv_activation', 'mish')\n",
    "    }\n",
    "    \n",
    "    return model_path, config\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef267348",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_test_data():\n",
    "    \"\"\"Load the test dataset\"\"\"\n",
    "    # Define transforms for test data\n",
    "    test_transform = transforms.Compose([\n",
    "        transforms.Resize((IMAGE_SIZE, IMAGE_SIZE)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "    ])\n",
    "    \n",
    "    # Load test dataset\n",
    "    test_dataset = iNaturalistDataset(root_dir=TEST_DIR, transform=test_transform)\n",
    "    \n",
    "    # Create data loader\n",
    "    test_loader = DataLoader(\n",
    "        test_dataset,\n",
    "        batch_size=32,\n",
    "        shuffle=False,\n",
    "        num_workers=4,\n",
    "        pin_memory=True\n",
    "    )\n",
    "    \n",
    "    return test_loader, test_dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3eee38a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(sweep_id='uf2dfd5t', entity='da24m008-iit-madras', project='DA6401-A2-V4'):\n",
    "    \"\"\"Evaluate the best model on the test set\"\"\"\n",
    "    # Initialize wandb\n",
    "    wandb.init(project=project, job_type=\"evaluation\")\n",
    "    \n",
    "    try:\n",
    "        # Get the best run and download its model\n",
    "        best_run = get_best_run_from_sweep(\n",
    "            sweep_id=sweep_id,\n",
    "            entity=entity,\n",
    "            project=project\n",
    "        )\n",
    "\n",
    "        model_path, best_config = download_best_model(best_run)\n",
    "        \n",
    "        # Log the best run information\n",
    "        wandb.log({\"best_run_id\": best_run.id, \"best_run_name\": best_run.name})\n",
    "        \n",
    "        # Load test data\n",
    "        test_loader, test_dataset = load_test_data()\n",
    "        \n",
    "        # Get class names and count\n",
    "        class_names = test_dataset.classes\n",
    "        num_classes = len(class_names)\n",
    "        print(f\"Number of classes: {num_classes}\")\n",
    "        print(f\"Class names: {class_names}\")\n",
    "        \n",
    "        # Update config with the correct number of classes\n",
    "        best_config['num_classes'] = num_classes\n",
    "        \n",
    "        # Create model with the best configuration\n",
    "        if best_config['filter_organization'] == 'same':\n",
    "            filters = [best_config['base_filters']] * 5\n",
    "        elif best_config['filter_organization'] == 'doubling':\n",
    "            filters = [best_config['base_filters'] * (2**i) for i in range(5)]\n",
    "        elif best_config['filter_organization'] == 'halving':\n",
    "            filters = [best_config['base_filters'] * (2**(4-i)) for i in range(5)]\n",
    "        else:\n",
    "            filters = [32, 64, 128, 256, 512]  # Default\n",
    "        \n",
    "        model = CNNModel(\n",
    "            input_channels=3,\n",
    "            num_classes=num_classes,\n",
    "            filters_per_layer=filters,\n",
    "            kernel_size=3,\n",
    "            conv_activation=best_config['conv_activation'],\n",
    "            dense_units=best_config['dense_neurons'],\n",
    "            dropout_rate=best_config['dropout_rate'],\n",
    "            use_batch_norm=best_config['use_batch_norm'],\n",
    "            dense_activation=best_config['dense_activation']\n",
    "        )\n",
    "        \n",
    "        # Load the best model weights\n",
    "        model.load_state_dict(torch.load(model_path, map_location=device))\n",
    "        model = model.to(device)\n",
    "        model.eval()  # Set to evaluation mode\n",
    "        \n",
    "        # Evaluate model\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        all_labels = []\n",
    "        all_predictions = []\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for inputs, labels in test_loader:\n",
    "                inputs, labels = inputs.to(device), labels.to(device)\n",
    "                outputs = model(inputs)\n",
    "                _, predicted = outputs.max(1)\n",
    "                \n",
    "                total += labels.size(0)\n",
    "                correct += predicted.eq(labels).sum().item()\n",
    "                \n",
    "                # Store for confusion matrix\n",
    "                all_labels.extend(labels.cpu().numpy())\n",
    "                all_predictions.extend(predicted.cpu().numpy())\n",
    "        \n",
    "        test_accuracy = correct / total\n",
    "        print(f\"Test accuracy: {test_accuracy:.4f}\")\n",
    "        \n",
    "        # Log to wandb\n",
    "        wandb.log({\n",
    "            \"best_model_test_accuracy\": test_accuracy\n",
    "        })\n",
    "        \n",
    "        return model, test_loader, test_dataset, all_labels, all_predictions, class_names\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Error during evaluation: {e}\")\n",
    "        raise e\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5aa0060",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_prediction_grid(model, test_dataset, class_names):\n",
    "    \"\"\"Create a 10x3 grid of test images with predictions\"\"\"\n",
    "    # Set model to evaluation mode\n",
    "    model.eval()\n",
    "    \n",
    "    # Define transform for visualization\n",
    "    vis_transform = transforms.Compose([\n",
    "        transforms.Resize((IMAGE_SIZE, IMAGE_SIZE)),\n",
    "        transforms.ToTensor(),\n",
    "    ])\n",
    "    \n",
    "    # Sample indices for the grid\n",
    "    num_samples = min(30, len(test_dataset))  # 10x3 grid needs 30 images\n",
    "    indices = np.random.choice(len(test_dataset), num_samples, replace=False)\n",
    "    \n",
    "    # Create figure for the grid\n",
    "    plt.figure(figsize=(15, 25))\n",
    "    \n",
    "    # Create lists to store images and captions for wandb\n",
    "    wandb_images = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for i, idx in enumerate(indices):\n",
    "            # Get image and label\n",
    "            original_image, label = test_dataset[idx]\n",
    "            \n",
    "            # For visualization, we need the unnormalized image\n",
    "            img_path = test_dataset.image_paths[idx]\n",
    "            vis_image = Image.open(img_path).convert('RGB')\n",
    "            vis_tensor = vis_transform(vis_image)\n",
    "            \n",
    "            # Move to device and add batch dimension\n",
    "            input_tensor = original_image.unsqueeze(0).to(device)\n",
    "            \n",
    "            # Get prediction\n",
    "            output = model(input_tensor)\n",
    "            _, prediction = output.max(1)\n",
    "            prediction = prediction.item()\n",
    "            \n",
    "            # Plot\n",
    "            plt.subplot(10, 3, i+1)\n",
    "            # Convert tensor to numpy for plotting\n",
    "            img_array = vis_tensor.permute(1, 2, 0).numpy()\n",
    "            plt.imshow(img_array)\n",
    "            \n",
    "            true_class = class_names[label]\n",
    "            pred_class = class_names[prediction]\n",
    "            \n",
    "            if label == prediction:\n",
    "                color = 'green'\n",
    "                caption = f\"True: {true_class} | Pred: {pred_class} ✓\"\n",
    "            else:\n",
    "                color = 'red'\n",
    "                caption = f\"True: {true_class} | Pred: {pred_class} ✗\"\n",
    "            \n",
    "            plt.title(caption, color=color)\n",
    "            plt.axis('off')\n",
    "            \n",
    "            # Add to wandb images list\n",
    "            wandb_images.append(wandb.Image(img_array, caption=caption))\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    \n",
    "    # Save the figure\n",
    "    plt.savefig('prediction_grid.png')\n",
    "    \n",
    "    # Log the figure to wandb\n",
    "    wandb.log({\"prediction_grid\": wandb.Image('prediction_grid.png')})\n",
    "    \n",
    "    # Also log the individual images with captions\n",
    "    wandb.log({\"test_predictions\": wandb_images})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28972a5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_confusion_matrix(all_labels, all_predictions, class_names):\n",
    "    \"\"\"Create and log a confusion matrix\"\"\"\n",
    "    # Create confusion matrix\n",
    "    cm = confusion_matrix(all_labels, all_predictions)\n",
    "    disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=class_names)\n",
    "    \n",
    "    plt.figure(figsize=(12, 10))\n",
    "    disp.plot(cmap=plt.cm.Blues)\n",
    "    plt.xticks(rotation=90)\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    # Save the figure\n",
    "    plt.savefig('confusion_matrix.png')\n",
    "    \n",
    "    # Log the figure to wandb\n",
    "    wandb.log({\"confusion_matrix\": wandb.Image('confusion_matrix.png')})\n",
    "    \n",
    "    # Also log a summary of class-wise accuracies\n",
    "    class_accuracy = cm.diagonal() / cm.sum(axis=1)\n",
    "    for i, (class_name, accuracy) in enumerate(zip(class_names, class_accuracy)):\n",
    "        wandb.log({f\"class_accuracy/{class_name}\": accuracy})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d97e6f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_classification_report(all_labels, all_predictions, class_names):\n",
    "    \"\"\"Generate and log classification report\"\"\"    \n",
    "    # Generate report\n",
    "    report = classification_report(all_labels, all_predictions, \n",
    "                                  target_names=class_names, \n",
    "                                  output_dict=True)\n",
    "    \n",
    "    # Log to wandb\n",
    "    for class_name in class_names:\n",
    "        if class_name in report:\n",
    "            wandb.log({\n",
    "                f\"metrics/{class_name}/precision\": report[class_name]['precision'],\n",
    "                f\"metrics/{class_name}/recall\": report[class_name]['recall'],\n",
    "                f\"metrics/{class_name}/f1-score\": report[class_name]['f1-score']\n",
    "            })\n",
    "    \n",
    "    # Log overall metrics\n",
    "    wandb.log({\n",
    "        \"metrics/accuracy\": report['accuracy'],\n",
    "        \"metrics/macro_avg_precision\": report['macro avg']['precision'],\n",
    "        \"metrics/macro_avg_recall\": report['macro avg']['recall'],\n",
    "        \"metrics/macro_avg_f1\": report['macro avg']['f1-score'],\n",
    "        \"metrics/weighted_avg_precision\": report['weighted avg']['precision'],\n",
    "        \"metrics/weighted_avg_recall\": report['weighted avg']['recall'],\n",
    "        \"metrics/weighted_avg_f1\": report['weighted avg']['f1-score']\n",
    "    })\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a91b0427",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate model\n",
    "model, test_loader, test_dataset, all_labels, all_predictions, class_names = evaluate_model(\n",
    "    sweep_id='uf2dfd5t',\n",
    "    entity='da24m008-iit-madras',\n",
    "    project='DA6401-A2-V4'\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40e0dacd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create prediction grid\n",
    "create_prediction_grid(model, test_dataset, class_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b3dc48c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create confusion matrix\n",
    "create_confusion_matrix(all_labels, all_predictions, class_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "408d029c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate classification report\n",
    "generate_classification_report(all_labels, all_predictions, class_names)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
